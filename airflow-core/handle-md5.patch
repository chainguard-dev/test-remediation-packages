diff --git a/airflow/lineage/hook.py b/airflow/lineage/hook.py
index 4ff35e4d9c..43f9cc9279 100644
--- a/airflow/lineage/hook.py
+++ b/airflow/lineage/hook.py
@@ -91,7 +91,7 @@ class HookLineageCollector(LoggingMixin):
         unique for each combination of dataset and context.
         """
         extra_str = json.dumps(dataset.extra, sort_keys=True)
-        extra_hash = hashlib.md5(extra_str.encode()).hexdigest()
+        extra_hash = hashlib.md5(extra_str.encode(), usedforsecurity=False).hexdigest()
         return f"{dataset.uri}_{extra_hash}_{id(context)}"
 
     def create_dataset(
diff --git a/airflow/models/dagbag.py b/airflow/models/dagbag.py
index 761a88c0ea..9a8ff3bb09 100644
--- a/airflow/models/dagbag.py
+++ b/airflow/models/dagbag.py
@@ -751,7 +751,7 @@ class DagBag(LoggingMixin):
 
 def generate_md5_hash(context):
     fileloc = context.get_current_parameters()["fileloc"]
-    return hashlib.md5(fileloc.encode()).hexdigest()
+    return hashlib.md5(fileloc.encode(), usedforsecurity=False).hexdigest()
 
 
 class DagPriorityParsingRequest(Base):
diff --git a/airflow/www/extensions/init_cache.py b/airflow/www/extensions/init_cache.py
index 84d952dd71..4fc54c8823 100644
--- a/airflow/www/extensions/init_cache.py
+++ b/airflow/www/extensions/init_cache.py
@@ -25,7 +25,7 @@ from airflow.configuration import conf
 from airflow.exceptions import AirflowConfigException
 
 HASH_METHOD_MAPPING = {
-    "md5": hashlib.md5,
+    "md5": lambda data: hashlib.md5(data, usedforsecurity=False),  # Use lambda to wrap MD5
     "sha1": hashlib.sha1,
     "sha224": hashlib.sha224,
     "sha256": hashlib.sha256,
@@ -33,7 +33,6 @@ HASH_METHOD_MAPPING = {
     "sha512": hashlib.sha512,
 }
 
-
 def init_cache(app):
     webserver_caching_hash_method = conf.get(
         section="webserver", key="CACHING_HASH_METHOD", fallback="md5"
